- Dealing with Memory Leaks:

There's a ton of reasons why an application may request a lot of memory. 

Sometimes, it's what we need for the program to complete it's task. 
Sometimes, it's caused by a part of the software misbehaving. 

First, let's trigger the misbehavior ourselves to see what this looks like. We'll use a terminal called "uxterm" for that.

"""
$ uxterm &
[1] 16086
"""

We've configured this terminal to have a really long scroll buffer. 

- Scroll buffer: 
Feature that lets us scroll up and see the things that we executed and their output.

The contents of the buffer are kept in memory. So if we make it really long and we managed to fill it, will cause our computer to run out of memory. 

With normal use, it might take ages until it happens, but if we run a command that keeps generating a lot of output, we could manage to fill that buffer pretty quickly. 
Say we run a command like:

"""
$ od -cx /dev/urandom
"""

This command will take the random numbers generated by the "urandom" device and show them as both characters and hexadecimal numbers. 
Since the "urandom" device keeps giving more and more random numbers, it will just keep going. Our command is filling up the "scroll buffer", making our computer require more and more memory. 

In a different terminal, let's open "top" and check out what's going on:

"""
$ top
"""

Pressing "Shift+M" we tell "top" that we want to order the programs by how much memory they are using. 
We see that the percentage of memory used by "xterm" is going up super quickly. 
Let's stop the process it's filling up the buffer by pressing "Control+C".

With that, we stopped the command that was filling the buffer, but the terminal still has that memory allocated, storing all the lines in the scroll buffer. 

Let's look at the output of top in a bit more detail. 

There's a bunch of different columns with data about each process: 
- "RES" is the dynamic memory that's preserved for the specific process. 
- "SHR" is for memory that's shared across processes. 
- "VIRT" lists all the virtual memory allocated for each process. 
  This includes; process specific memory, shared memory, and other shared resources that are stored on disk but maps into the memory of the process.

It's usually fine for a process to have a high value in the "VIRT" column. 
The one that usually indicates a problem is the "RES" column. 

Let's close the other terminal so that it releases all the memory that it reserved.

In this example, we saw what a program that keeps requesting more and more memory looks like. This was a super extreme example. 
Most memory leaks don't happen at that speed. It can usually take a long while until we notice that a program is taking more memory than it should, and it might be hard to tell the difference between memory that's actually needed and memory that's being wasted. 

But looking at the output of "top" and comparing it to what it used to be a while back is usually how any investigation into a memory leak starts. 

- Different example: 
We have a script that analyzes the frequency of words in web pages. 
This script works fine when it's just a few web pages, but if we try to give it all the Wikipedia contents, it starts using up all the memory. 

Let's run it first and see what happens.

"""
$ ./contents_stats.py
"""

This is running and it will take a long while to finish. It's processing a huge amount of articles after all. While this is running, let's look at the output of "top" in a different terminal and see what we find.

"""
$ top
"""

We see that there's a bunch of different "contents_stats" processes running. That's because our script is using the "multiprocessing" techniques that we saw in an earlier module, to parallelize the processing of the information and get the results as fast as possible. 

It seems like these scripts are taking a lot of memory. So let's sort it out to see the details. (Shift+M)

We see that the memory used by one of the processes in particular keeps growing and growing. The application is processing a bunch of data and generating a dictionary with it, so it's expected that it will use some memory but not this much. 
This looks like the program is storing more than it should in memory. This program is pretty complex. So we could use the help of a memory profiler here to figure out what the problem is.

Let's stop it now (CTRL+C) and use a profiler to figure out where our computer's memory is going. To do that, we'll need to use a simplified version of our code as profiling the memory of a multi-process application is extra hard, and instead of processing all the articles, we'll just handle a few so that we can check up the memory consumption quickly. 

Let's open our simplified script and have a look.

"""
$ atom contents_stats_simple.py
"""

We'll be using a module called "memory_profiler". This is one of the many different memory profilers available for Python.

We've added this "@profile" label before the main function definition to tell the profiler that we wanted to analyze the memory consumption of it. 
This type of label is called a "decorator" 

- Decorator:
Used in Python to add extra behavior to functions without having to modify the code. 

In this case, the extra behavior is measuring the use of memory. The rest of the code is basically the same as the original one, it just uses a single process and is limited to 50 articles instead of the thousands of articles that the other script was going through.

"""
$ ./contents_stats_simple.py
"""

We're running the script with the memory profiler enabled. This is just reading through 50 articles but it takes a bunch of time because all that memory profiling makes our script slower. 
Once the program finishes, the memory profiler gives us information about which lines are adding or removing data from the memory used by the program. 

The first column shows us the amount of memory required when each line gets executed. 
The second one shows the increase in memory for each specific line. 

We see here that after going through 50 articles, the program already took 
130 megabytes, no wonder we ran out of memory when we were trying to process all the articles. 
We can see that the variables that require the most memory are "article" and "text", with about 4 and 3 megabytes respectively. Those are the articles we're processing, and it's fine for them to take space while we're counting the words in the article. 
But once were done processing one article, we shouldn't keep that memory around. 

- Can you spot the problem?
Right at the end, the code is storing the "article" to keep a reference to it, but it's storing the "whole article". If we want to keep a reference to all the articles that include a word, we could store the "titles" or the "index" entries, definitely NOT the whole content. 

There's a ton more to say about memory management and memory profiling that we don't have time to cover here. In the next reading, we've gathered a bunch of interesting links to information about managing scarce resources.