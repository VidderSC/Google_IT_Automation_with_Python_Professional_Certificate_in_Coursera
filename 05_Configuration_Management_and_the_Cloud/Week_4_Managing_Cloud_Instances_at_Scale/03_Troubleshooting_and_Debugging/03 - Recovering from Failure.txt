- Recovering from Failure:

When dealing with a complex system, there's a lot of ways it can fail. 

If we want our service to be reliable, we need to make sure that we can get it up and running as quickly as possible when bad things happen, we'll need to have good backups and a well-documented recovery plan. 

Backups here doesn't mean just copies of your data. 
It also means backups for the different pieces of your "infrastructure", including the "instances" that are running the service and the "network" that's used to connect to the service. 

Backups of the data your service handles are extremely important. 

If you operate a service that stores any kind of data, it's critical that you implement automatic backups and that you periodically check that those backups are working correctly by performing "restores". This helps make sure that you're backing up the right data and that you have well-documented processes for recovering it when things fail. 

- What about the rest of the infrastructure?
If you store all your infrastructure as code, you already have a backup of what your infrastructure should look like, but if your service goes down for some reason, deploying all that infrastructure from scratch might take awhile.

That's why many teams keep backup or secondary instances of their services already up and running. 
That way, if there's a problem with the primary instance, they can simply point the load balancer or the DNS entries to the secondary instance with minimal disruption to the service. 

Alternatively, it's common practice to have enough servers running at any time so that if one of them goes down, the others can still handle the traffic. 
Or on a larger scale, have the service running on different data centers around the world, so that if one of the data centers has a problem, the service can still be provided by the instances running in the other data centers. 

If you're running a service on-premise, you might want to have two different connections to the Internet, this way, if the connection offered by one of your "ISPs" (Internet Service Providers) goes down, you can still connect to the Internet through the other one. 

When you're running on Cloud, you can mostly rely on your Cloud provider having enough network redundancy, but if you really care about your service staying up no matter what, you might want to run your service on two different Cloud vendors so that if one of the providers has a large outage, you can still rely on the other. 

Imagine you're running your service in one data center, unfortunately, that data center has just suffered a natural disaster and all of your instances are down. 

- What do you do? 
First step, take a deep breath and don't panic. 

You need to recover your service from scratch, deploying it in a different data center and getting all your data from backups. 
As long as the backups are available in other data centers and your infrastructure is fully stored in a version control system, this should be possible. 

But figuring out how to successfully bring up the whole system from scratch can take a while, so you don't want to have to scramble to do it when disaster hits. Instead, you should have a documented procedure that explains all of the steps that you need to take. 

Since systems evolve over time, you need to make sure that this documentation stays up-to-date. One way to do that is to once in a while pretend that you need to recover your service, follow the documented steps, and check if anything is missing or outdated. 

Systems will fail. A 100% availability is simply not an achievable targets, but being prepared for a failure will let you recover your service quickly and keep your users happy.